#  PrÃ©diction CTR Multimodale sur MicroLens-1M 
## ğŸ“Œ AperÃ§u du Projet

Ce dÃ©pÃ´t contient la solution pour la **CompÃ©tition de PrÃ©diction du Taux de Clics Multimodaux (CTR)** basÃ©e sur le jeu de donnÃ©es **MicroLens-1M**.

L'objectif de ce projet est de prÃ©dire la probabilitÃ© qu'un utilisateur clique sur un Ã©lÃ©ment spÃ©cifique (vidÃ©o/article) en se basant sur :
- **Historique Utilisateur :**  Comportement sÃ©quentiel (clics passÃ©s).
- **Contenu de l'Ã‰lÃ©ment :** CaractÃ©ristiques multimodales (Titres Textuels + Couvertures Images).

Notre approche met en Å“uvre un **Pipeline d'Optimisation en Cascade** combinant de Grands ModÃ¨les Vision-Langage (CLIP) pour l'extraction de caractÃ©ristiques et des RÃ©seaux d'IntÃ©rÃªt Profond (DIN) pour la prÃ©diction du CTR.

## ğŸ—ï¸ Architecture & MÃ©thodologie
La solution est divisÃ©e en trois tÃ¢ches stratÃ©giques :

### TÃ¢che 1 : Apprentissage de ReprÃ©sentation Multimodale (Offline)

Au lieu d'utiliser des embeddings de base fixes, nous avons optimisÃ© les reprÃ©sentations des Ã©lÃ©ments pour capturer de meilleurs signaux sÃ©mantiques.

- **ModÃ¨le :** openai/clip-vit-base-patch32 (Vision Transformer).
- **Technique :** Fine-tuning de CLIP sur les donnÃ©es d'interaction utilisateur-Ã©lÃ©ment (Label 1 = Paire positive, Label 0 = Paire nÃ©gative) pour aligner l'espace visuel/textuel avec les prÃ©fÃ©rences des utilisateurs.
- **RÃ©duction de DimensionnalitÃ© :** Compression des embeddings 1280D (Texte+Image) vers 128D en utilisant une PCA/Autoencodeur pour correspondre aux exigences d'entrÃ©e du modÃ¨le CTR.
### 2. TÃ¢che 2 : Optimisation du ModÃ¨le CTR (Online)

Nous avons utilisÃ© des architectures de recommandation de pointe pour modÃ©liser les intÃ©rÃªts des utilisateurs.

- **ModÃ¨le :** DIN (Deep Interest Network).
- **Pourquoi DIN ?** Il utilise un mÃ©canisme d'attention pour activer uniquement les parties de l'historique utilisateur qui sont pertinentes pour l'Ã©lÃ©ment candidat actuel.
- **Framework :** ImplÃ©mentÃ© avec FuxiCTR.
- **RÃ©glage des HyperparamÃ¨tres :** Optimisation de la Taille du Batch, du Taux d'Apprentissage et du Dropout pour prÃ©venir le Surapprentissage et les erreurs OOM (Out Of Memory) sur GPU.

### 3. TÃ¢che 1 & 2 : Fusion en Cascade

La soumission finale combine les forces des deux tÃ¢ches :

- **Ã‰tape A :** GÃ©nÃ©rer des embeddings multimodaux optimisÃ©s en utilisant le CLIP fine-tunÃ© (TÃ¢che 1).

- **Ã‰tape B :** Injecter ces embeddings dans le modÃ¨le DIN (TÃ¢che 2) en tant que vecteurs de caractÃ©ristiques denses.

- **Ã‰tape C :** EntraÃ®ner le modÃ¨le CTR de bout en bout pour exploiter les riches informations sÃ©mantiques.

## ğŸ› ï¸ Architecture

<img width="1261" height="1364" alt="diagram-export-20-12-2025-12_45_52" src="https://github.com/user-attachments/assets/ca8ea7d4-4550-460c-906a-15632be4201f" />




## ğŸ“¦ ğŸ› ï¸ Installation & Configuration


### 1. Clone the Repository

```bash
git clone https://github.com/oumniya03/Projet-rag.git
cd Projet-rag
```

### 2. Configure Environment Variables

For security reasons, API keys are not stored in the repository. You must create a `.env` file at the root of the project.

Create a file named `.env` and add your Groq API Key:

```env
GROQ_API_KEY=gsk_your_groq_api_key_here
```

> **Note:** You can obtain a Groq API key from [https://console.groq.com](https://console.groq.com)

### 3. Run with Docker Script

The project includes a helper script `docker.sh` as requested in the challenge requirements.

**Start the application:**

```bash
chmod +x docker.sh  # Only needed the first time (Linux/Mac/GitBash)
./docker.sh up
```

> **Note:** The first launch may take a few minutes to build the images and download the embedding model.

### 4. Access the Application

Once the containers are running, you can access:

* **Frontend (Chat UI):** [http://localhost:3000](http://localhost:3000)
* **Backend (API Docs):** [http://localhost:8000/docs](http://localhost:8000/docs)

## ğŸ”§ Management Commands (docker.sh)

| Command | Description |
|---------|-------------|
| `./docker.sh up` | Builds and starts the containers in the background |
| `./docker.sh down` | Stops and removes containers and networks |
| `./docker.sh build` | Rebuilds the images (useful after code changes) |
| `./docker.sh logs` | Displays real-time logs from backend and frontend |


## ğŸ“‚ Project Structure

```
Projet-rag/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # FastAPI Application & RAG Logic
â”‚   â”œâ”€â”€ Dockerfile           # Backend Container Configuration
â”‚   â””â”€â”€ requirements.txt     # Python Dependencies
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â””â”€â”€ page.tsx         # Main Chat Interface (React/Next.js)
â”‚   â”œâ”€â”€ Dockerfile           # Frontend Container Configuration
â”‚   â””â”€â”€ tailwind.config.ts   # Styling Configuration
â”œâ”€â”€ data/                    # Persisted Data (Indices & Uploads)
â”œâ”€â”€ docker-compose.yml       # Docker Orchestration
â”œâ”€â”€ docker.sh                # Management Script
â”œâ”€â”€ .env                     # Environment Variables (create this)
â””â”€â”€ README.md                # This file
```



## ğŸ“ Usage Guide

### Uploading Documents

1. Navigate to [http://localhost:3000](http://localhost:3000)
2. Use the upload interface to add your documents
3. Wait for the processing confirmation

### Asking Questions

1. Type your question in the chat interface
2. Press Enter or click Send
3. View the AI-generated answer with source references

### API Integration

You can integrate the backend API into your own applications:

```python
import requests

response = requests.post(
    "http://localhost:8000/ask",
    json={"question": "Your question here"}
)

answer = response.json()["answer"]
sources = response.json()["sources"]
```

## ğŸ” Troubleshooting

### Port Already in Use

If ports 3000 or 8000 are already in use:

```bash
# Modify docker-compose.yml to use different ports
# Change "3000:3000" to "3001:3000" for frontend
# Change "8000:8000" to "8001:8000" for backend
```

### Container Build Failures

```bash
./docker.sh down
docker system prune -a
./docker.sh build
./docker.sh up
```

### Missing Environment Variables

Ensure your `.env` file exists and contains:
```env
GROQ_API_KEY=your_actual_key_here
```

## ğŸ¤ Contributing

This is a challenge submission project. For questions or feedback, please contact the author.


## ğŸ‘¤ Author

**Oumniya**

- GitHub: [@oumniya03](https://github.com/oumniya03)
- Project: [Projet-rag](https://github.com/oumniya03/Projet-rag)

## ğŸ¯ Challenge Requirements Met

- âœ… Dockerized application with `docker.sh` script
- âœ… RAG implementation with document retrieval
- âœ… `/ask` endpoint with proper response format
- âœ… Evaluation script for quality assessment
- âœ… Modern, responsive frontend interface
- âœ… Complete documentation

---



*Built  using FastAPI, Next.js, and Docker*

